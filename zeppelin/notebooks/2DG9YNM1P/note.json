{
  "paragraphs": [
    {
      "text": "%md\n# Anomaly Detection\n#### author: Loan Lassalle",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:39 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eAnomaly Detection\u003c/h1\u003e\n\u003ch4\u003eauthor: Loan Lassalle\u003c/h4\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1529998491856_-2147449320",
      "id": "20180626-073451_426975331",
      "dateCreated": "Jun 26, 2018 7:34:51 AM",
      "dateStarted": "Sep 11, 2018 3:20:39 PM",
      "dateFinished": "Sep 11, 2018 3:20:39 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Loading data",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:39 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eLoading data\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530016014058_1331767191",
      "id": "20180626-122654_1915337111",
      "dateCreated": "Jun 26, 2018 12:26:54 PM",
      "dateStarted": "Sep 11, 2018 3:20:39 PM",
      "dateFinished": "Sep 11, 2018 3:20:39 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val dataWithoutHeader \u003d spark\n  .read\n  .option(\"inferSchema\", true)\n  .option(\"header\", false)\n  .csv(\"/data/kddcup_1999_network_dataset/partially/kddcup.data_10_percent_corrected\")\n\ndataWithoutHeader.count()",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 5:53:39 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "tableHide": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "dataWithoutHeader: org.apache.spark.sql.DataFrame \u003d [_c0: int, _c1: string ... 40 more fields]\nres141: Long \u003d 494021\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1529998521426_-1879633437",
      "id": "20180626-073521_364480744",
      "dateCreated": "Jun 26, 2018 7:35:21 AM",
      "dateStarted": "Sep 11, 2018 3:20:40 PM",
      "dateFinished": "Sep 11, 2018 3:20:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val data \u003d dataWithoutHeader.toDF(\n  \"duration\", \"protocol_type\", \"service\", \"flag\",\n  \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n  \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n  \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n  \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n  \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\",\n  \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n  \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n  \"dst_host_count\", \"dst_host_srv_count\",\n  \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n  \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n  \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n  \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n  \"label\")",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "data: org.apache.spark.sql.DataFrame \u003d [duration: int, protocol_type: string ... 40 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1529999252462_-1147381304",
      "id": "20180626-074732_1808920546",
      "dateCreated": "Jun 26, 2018 7:47:32 AM",
      "dateStarted": "Sep 11, 2018 3:20:40 PM",
      "dateFinished": "Sep 11, 2018 3:20:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "data.select(\"label\")\n  .groupBy(\"label\")\n  .count()\n  .orderBy($\"count\".desc)\n  .show(25)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+------+\n|           label| count|\n+----------------+------+\n|          smurf.|280790|\n|        neptune.|107201|\n|         normal.| 97278|\n|           back.|  2203|\n|          satan.|  1589|\n|        ipsweep.|  1247|\n|      portsweep.|  1040|\n|    warezclient.|  1020|\n|       teardrop.|   979|\n|            pod.|   264|\n|           nmap.|   231|\n|   guess_passwd.|    53|\n|buffer_overflow.|    30|\n|           land.|    21|\n|    warezmaster.|    20|\n|           imap.|    12|\n|        rootkit.|    10|\n|     loadmodule.|     9|\n|      ftp_write.|     8|\n|       multihop.|     7|\n|            phf.|     4|\n|           perl.|     3|\n|            spy.|     2|\n+----------------+------+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1529999320415_711042372",
      "id": "20180626-074840_53027367",
      "dateCreated": "Jun 26, 2018 7:48:40 AM",
      "dateStarted": "Sep 11, 2018 3:20:45 PM",
      "dateFinished": "Sep 11, 2018 3:20:48 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### A First Take on Clustering",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eA First Take on Clustering\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1529998587544_1733466863",
      "id": "20180626-073627_2145790578",
      "dateCreated": "Jun 26, 2018 7:36:27 AM",
      "dateStarted": "Sep 11, 2018 3:20:40 PM",
      "dateFinished": "Sep 11, 2018 3:20:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import scala.util.Random\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.clustering.{KMeans, KMeansModel}\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler}\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.sql.DataFrame",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import scala.util.Random\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.clustering.{KMeans, KMeansModel}\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler}\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.sql.DataFrame\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530017890384_-514209891",
      "id": "20180626-125810_854618638",
      "dateCreated": "Jun 26, 2018 12:58:10 PM",
      "dateStarted": "Sep 11, 2018 3:20:45 PM",
      "dateFinished": "Sep 11, 2018 3:20:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val numericOnly \u003d data.drop(\"protocol_type\", \"service\", \"flag\").cache()",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "numericOnly: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [duration: int, src_bytes: int ... 37 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530015949846_858248564",
      "id": "20180626-122549_1014889477",
      "dateCreated": "Jun 26, 2018 12:25:49 PM",
      "dateStarted": "Sep 11, 2018 3:20:49 PM",
      "dateFinished": "Sep 11, 2018 3:20:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Clustering, Take 0",
      "text": "def fitPipeline0(data: DataFrame): PipelineModel \u003d {\n  val assembler \u003d new VectorAssembler()\n    .setInputCols(data.columns.filter(_ !\u003d \"label\"))\n    .setOutputCol(\"featureVector\")\n\n  val kMeans \u003d new KMeans()\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"featureVector\")\n\n  val pipeline \u003d new Pipeline().setStages(Array(assembler, kMeans))\n  pipeline.fit(data)\n}\n\ndef clusteringTake0(data: DataFrame): Unit \u003d {\n  val model \u003d fitPipeline0(data)\n  val kMeansModel \u003d model.stages.last.asInstanceOf[KMeansModel]\n  kMeansModel.clusterCenters.foreach(println)\n \n  val withCluster \u003d model.transform(numericOnly)\n  withCluster.select(\"cluster\", \"label\")\n    .groupBy(\"cluster\", \"label\").count()\n    .orderBy($\"cluster\", $\"count\".desc)\n    .show(25)\n}\n\nclusteringTake0(numericOnly)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "fitPipeline0: (data: org.apache.spark.sql.DataFrame)org.apache.spark.ml.PipelineModel\nclusteringTake0: (data: org.apache.spark.sql.DataFrame)Unit\n[47.979395571029514,1622.078830816566,868.5341828266062,4.453261001578883E-5,0.006432937937735314,1.4169466823205539E-5,0.03451682118132869,1.5181571596291647E-4,0.14824703453301485,0.01021213716043885,1.1133152503947209E-4,3.6435771831099954E-5,0.011351767134933808,0.0010829521072021374,1.0930731549329986E-4,0.0010080563539937655,0.0,0.0,0.0013865835391279706,332.2862475203433,292.9071434354884,0.17668541759442943,0.17660780940042914,0.05743309987449898,0.05771839196793656,0.7915488441762945,0.020981640419421355,0.028996862475203923,232.4707319541719,188.6660459090725,0.7537812031901686,0.030905611108870867,0.6019355289259973,0.006683514837454898,0.17675395732966057,0.1764416217966883,0.05811762681672766,0.057411116958826745]\n[2.0,6.9337564E8,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,57.0,3.0,0.79,0.67,0.21,0.33,0.05,0.39,0.0,255.0,3.0,0.01,0.09,0.22,0.0,0.18,0.67,0.05,0.33]\n+-------+----------------+------+\n|cluster|           label| count|\n+-------+----------------+------+\n|      0|          smurf.|280790|\n|      0|        neptune.|107201|\n|      0|         normal.| 97278|\n|      0|           back.|  2203|\n|      0|          satan.|  1589|\n|      0|        ipsweep.|  1247|\n|      0|      portsweep.|  1039|\n|      0|    warezclient.|  1020|\n|      0|       teardrop.|   979|\n|      0|            pod.|   264|\n|      0|           nmap.|   231|\n|      0|   guess_passwd.|    53|\n|      0|buffer_overflow.|    30|\n|      0|           land.|    21|\n|      0|    warezmaster.|    20|\n|      0|           imap.|    12|\n|      0|        rootkit.|    10|\n|      0|     loadmodule.|     9|\n|      0|      ftp_write.|     8|\n|      0|       multihop.|     7|\n|      0|            phf.|     4|\n|      0|           perl.|     3|\n|      0|            spy.|     2|\n|      1|      portsweep.|     1|\n+-------+----------------+------+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530018658049_-89513859",
      "id": "20180626-131058_522806842",
      "dateCreated": "Jun 26, 2018 1:10:58 PM",
      "dateStarted": "Sep 11, 2018 3:20:49 PM",
      "dateFinished": "Sep 11, 2018 3:21:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Choosing k",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eChoosing k\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530004121722_-591267022",
      "id": "20180626-090841_1946012157",
      "dateCreated": "Jun 26, 2018 9:08:41 AM",
      "dateStarted": "Sep 11, 2018 3:20:40 PM",
      "dateFinished": "Sep 11, 2018 3:20:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Clustering, Take 1",
      "text": "def clusteringScore1(data: DataFrame, k: Int): Double \u003d {\n  val assembler \u003d new VectorAssembler()\n    .setInputCols(data.columns.filter(_ !\u003d \"label\"))\n    .setOutputCol(\"featureVector\")\n        \n  val kMeans \u003d new KMeans()\n    .setSeed(Random.nextLong())\n    .setK(k)\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"featureVector\")\n        \n  val pipeline \u003d new Pipeline().setStages(Array(assembler, kMeans))\n  val model \u003d pipeline.fit(data)\n  val kMeansModel \u003d model.stages.last.asInstanceOf[KMeansModel]\n  kMeansModel.computeCost(assembler.transform(data)) / data.count()\n}\n\ndef clusteringTake1(data: DataFrame): Unit \u003d {\n  (20 to 100 by 20)\n    .map(k \u003d\u003e (k, clusteringScore1(data, k)))\n    .foreach(println)\n}\n\nclusteringTake1(numericOnly)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "title": true,
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "clusteringScore1: (data: org.apache.spark.sql.DataFrame, k: Int)Double\nclusteringTake1: (data: org.apache.spark.sql.DataFrame)Unit\n(20,1.896660041281414E7)\n(40,2.4030155377636874E8)\n(60,3.889552083695743E7)\n(80,6650195.286378146)\n(100,2.626282778093838E7)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530004360706_-1248297195",
      "id": "20180626-091240_948200329",
      "dateCreated": "Jun 26, 2018 9:12:40 AM",
      "dateStarted": "Sep 11, 2018 3:20:50 PM",
      "dateFinished": "Sep 11, 2018 3:22:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Clustering, Take 2",
      "text": "def clusteringScore2(data: DataFrame, k: Int): Double \u003d {\n  val assembler \u003d new VectorAssembler()\n    .setInputCols(data.columns.filter(_ !\u003d \"label\"))\n    .setOutputCol(\"featureVector\")\n        \n  val kMeans \u003d new KMeans()\n    .setSeed(Random.nextLong())\n    .setK(k)\n    .setMaxIter(40)\n    .setTol(1.0e-5)\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"featureVector\")\n        \n  val pipeline \u003d new Pipeline().setStages(Array(assembler, kMeans))\n  val model \u003d pipeline.fit(data)\n  val kMeansModel \u003d model.stages.last.asInstanceOf[KMeansModel]\n  kMeansModel.computeCost(assembler.transform(data)) / data.count()\n}\n\ndef clusteringTake2(data: DataFrame): Unit \u003d {\n  (20 to 100 by 20)\n    .map(k \u003d\u003e (k, clusteringScore2(data, k)))\n    .foreach(println)\n}\n\nclusteringTake2(numericOnly)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:40 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "title": true,
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "clusteringScore2: (data: org.apache.spark.sql.DataFrame, k: Int)Double\nclusteringTake2: (data: org.apache.spark.sql.DataFrame)Unit\n(20,5.505856809550381E7)\n(40,2.348790172662768E7)\n(60,3.376321134355672E7)\n(80,6991431.440124635)\n(100,9916160.707087679)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530004481570_-6511635",
      "id": "20180626-091441_1574207042",
      "dateCreated": "Jun 26, 2018 9:14:41 AM",
      "dateStarted": "Sep 11, 2018 3:21:05 PM",
      "dateFinished": "Sep 11, 2018 3:26:41 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Feature Normalization",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eFeature Normalization\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530005396122_-646876132",
      "id": "20180626-092956_1818203621",
      "dateCreated": "Jun 26, 2018 9:29:56 AM",
      "dateStarted": "Sep 11, 2018 3:20:41 PM",
      "dateFinished": "Sep 11, 2018 3:20:41 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Clustering, Take 3",
      "text": "def fitPipeline3(data: DataFrame, k: Int): PipelineModel \u003d {\n  val assembler \u003d new VectorAssembler()\n    .setInputCols(data.columns.filter(_ !\u003d \"label\"))\n    .setOutputCol(\"featureVector\")\n        \n  val scaler \u003d new StandardScaler()\n    .setWithStd(true)\n    .setWithMean(false)\n    .setInputCol(\"featureVector\")\n    .setOutputCol(\"scaledFeatureVector\")\n        \n  val kMeans \u003d new KMeans()\n    .setSeed(Random.nextLong())\n    .setK(k)\n    .setMaxIter(40)\n    .setTol(1.0e-5)\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"scaledFeatureVector\")\n        \n  val pipeline \u003d new Pipeline().setStages(Array(assembler, scaler, kMeans))\n  pipeline.fit(data)\n}\n\ndef clusteringScore3(data: DataFrame, k: Int): Double \u003d {\n  val model \u003d fitPipeline3(data, k)\n  val kMeansModel \u003d model.stages.last.asInstanceOf[KMeansModel]\n  kMeansModel.computeCost(model.transform(data)) / data.count()\n}\n\ndef clusteringTake3(data: DataFrame): Unit \u003d {\n  (60 to 270 by 30)\n    .map(k \u003d\u003e (k, clusteringScore3(numericOnly, k)))\n    .foreach(println)\n}\n\nclusteringTake3(numericOnly)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "title": true,
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "fitPipeline3: (data: org.apache.spark.sql.DataFrame, k: Int)org.apache.spark.ml.PipelineModel\nclusteringScore3: (data: org.apache.spark.sql.DataFrame, k: Int)Double\nclusteringTake3: (data: org.apache.spark.sql.DataFrame)Unit\n(60,1.1546536060555077)\n(90,0.7111377780727637)\n(120,0.486901925529336)\n(150,0.379809896066344)\n(180,0.3035265491172653)\n(210,0.2550432206743114)\n(240,0.22857069752618972)\n(270,0.20470543225898974)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530005692944_-1104285091",
      "id": "20180626-093452_110600592",
      "dateCreated": "Jun 26, 2018 9:34:52 AM",
      "dateStarted": "Sep 11, 2018 3:22:24 PM",
      "dateFinished": "Sep 11, 2018 3:33:54 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Categorical Variables",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eCategorical Variables\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530005951043_1517746371",
      "id": "20180626-093911_596564830",
      "dateCreated": "Jun 26, 2018 9:39:11 AM",
      "dateStarted": "Sep 11, 2018 3:20:41 PM",
      "dateFinished": "Sep 11, 2018 3:20:41 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Clustering, Take 4",
      "text": "def oneHotPipeline(inputCol: String): (Pipeline, String) \u003d {\n  val indexer \u003d new StringIndexer()\n    .setInputCol(inputCol)\n    .setOutputCol(inputCol + \"_indexed\")\n  \n  val encoder \u003d new OneHotEncoder()\n    .setInputCol(inputCol + \"_indexed\")\n    .setOutputCol(inputCol + \"_vec\")\n\n  val pipeline \u003d new Pipeline().setStages(Array(indexer, encoder))\n  (pipeline, inputCol + \"_vec\")\n}\n\ndef fitPipeline4(data: DataFrame, k: Int): PipelineModel \u003d {\n  val (protoTypeEncoder, protoTypeVecCol) \u003d oneHotPipeline(\"protocol_type\")\n  val (serviceEncoder, serviceVecCol) \u003d oneHotPipeline(\"service\")\n  val (flagEncoder, flagVecCol) \u003d oneHotPipeline(\"flag\")\n  \n  // Original columns, without label / string columns, but with new vector encoded cols\n  val assembleCols \u003d Set(data.columns: _*) -- \n    Seq(\"label\", \"protocol_type\", \"service\", \"flag\") ++\n    Seq(protoTypeVecCol, serviceVecCol, flagVecCol)\n      \n  val assembler \u003d new VectorAssembler()\n    .setInputCols(assembleCols.toArray)\n    .setOutputCol(\"featureVector\")\n    \n  val scaler \u003d new StandardScaler()\n    .setWithStd(true)\n    .setWithMean(false)\n    .setInputCol(\"featureVector\")\n    .setOutputCol(\"scaledFeatureVector\")\n    \n  val kMeans \u003d new KMeans()\n    .setSeed(Random.nextLong())\n    .setK(k)\n    .setMaxIter(40)\n    .setTol(1.0e-5)\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"scaledFeatureVector\")\n    \n  val pipeline \u003d new Pipeline().setStages(Array(protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kMeans))\n  pipeline.fit(data)\n}\n\ndef clusteringScore4(data: DataFrame, k: Int): Double \u003d {\n  val model \u003d fitPipeline4(data, k)\n  val kMeansModel \u003d model.stages.last.asInstanceOf[KMeansModel]\n  kMeansModel.computeCost(model.transform(data)) / data.count()\n}\n\ndef clusteringTake4(data: DataFrame): Unit \u003d {\n  (60 to 270 by 30)\n    .map(k \u003d\u003e (k, clusteringScore4(data, k)))\n    .foreach(println)\n}\n\nclusteringTake4(data)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "editorHide": false,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "oneHotPipeline: (inputCol: String)(org.apache.spark.ml.Pipeline, String)\nfitPipeline4: (data: org.apache.spark.sql.DataFrame, k: Int)org.apache.spark.ml.PipelineModel\nclusteringScore4: (data: org.apache.spark.sql.DataFrame, k: Int)Double\nclusteringTake4: (data: org.apache.spark.sql.DataFrame)Unit\n(60,32.77384676227396)\n(90,12.867544194615089)\n(120,3.1226239690419586)\n(150,1.983568546081176)\n(180,1.535028797825872)\n(210,1.164975576814356)\n(240,0.9933994340498153)\n(270,0.7773474041712077)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530006686921_2065088048",
      "id": "20180626-095126_2012873590",
      "dateCreated": "Jun 26, 2018 9:51:26 AM",
      "dateStarted": "Sep 11, 2018 3:26:41 PM",
      "dateFinished": "Sep 11, 2018 3:48:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Using Labels with Entropy",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eUsing Labels with Entropy\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530006790029_-1006808467",
      "id": "20180626-095310_1526218671",
      "dateCreated": "Jun 26, 2018 9:53:10 AM",
      "dateStarted": "Sep 11, 2018 3:20:41 PM",
      "dateFinished": "Sep 11, 2018 3:20:41 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Clustering, Take 5",
      "text": "def fitPipeline5(data: DataFrame, k: Int): PipelineModel \u003d {\n  val (protoTypeEncoder, protoTypeVecCol) \u003d oneHotPipeline(\"protocol_type\")\n  val (serviceEncoder, serviceVecCol) \u003d oneHotPipeline(\"service\")\n  val (flagEncoder, flagVecCol) \u003d oneHotPipeline(\"flag\")\n  \n  // Original columns, without label / string columns, but with new vector encoded cols\n  val assembleCols \u003d Set(data.columns: _*) -- \n    Seq(\"label\", \"protocol_type\", \"service\", \"flag\") ++\n    Seq(protoTypeVecCol, serviceVecCol, flagVecCol)\n      \n  val assembler \u003d new VectorAssembler()\n    .setInputCols(assembleCols.toArray)\n    .setOutputCol(\"featureVector\")\n    \n  val scaler \u003d new StandardScaler()\n    .setWithStd(true)\n    .setWithMean(false)\n    .setInputCol(\"featureVector\")\n    .setOutputCol(\"scaledFeatureVector\")\n    \n  val kMeans \u003d new KMeans()\n    .setSeed(Random.nextLong())\n    .setK(k)\n    .setMaxIter(40)\n    .setTol(1.0e-5)\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"scaledFeatureVector\")\n    \n  val pipeline \u003d new Pipeline().setStages(Array(protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kMeans))\n  pipeline.fit(data)\n}\n\ndef entropy(counts: Iterable[Int]): Double \u003d { \n  val values \u003d counts.filter(_ \u003e 0)\n  val n \u003d values.map(_.toDouble).sum\n    \n  values.map { v \u003d\u003e\n    val p \u003d v / n\n    -p * math.log(p)\n  }.sum\n}\n\ndef clusteringScore5(data: DataFrame, k: Int): Double \u003d {\n  val clusterLabel \u003d fitPipeline5(data, k).transform(data).select(\"cluster\", \"label\").as[(Int, String)]\n  \n  // Extract collections of labels, per cluster\n  val weightedClusterEntropy \u003d clusterLabel\n    .groupByKey { case (cluster, _) \u003d\u003e cluster }\n    .mapGroups { case (_, clusterLabels) \u003d\u003e\n      val labels \u003d clusterLabels.map { case (_, label) \u003d\u003e label }.toSeq \n      \n      // Count labels in collections\n      val labelCounts \u003d labels.groupBy(identity).values.map(_.size)\n      \n      labels.size * entropy(labelCounts)\n    }.collect()\n\n  // Average entropy weighted by cluster size\n  weightedClusterEntropy.sum / data.count()\n}\n\ndef clusteringTake5(data: DataFrame): Unit \u003d {\n  (60 to 270 by 30)\n    .map(k \u003d\u003e (k, clusteringScore5(data, k)))\n    .foreach(println)\n}\n\nclusteringTake5(data)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "title": true,
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "fitPipeline5: (data: org.apache.spark.sql.DataFrame, k: Int)org.apache.spark.ml.PipelineModel\nentropy: (counts: Iterable[Int])Double\nclusteringScore5: (data: org.apache.spark.sql.DataFrame, k: Int)Double\nclusteringTake5: (data: org.apache.spark.sql.DataFrame)Unit\n(60,0.07960532138245488)\n(90,0.04812576063637497)\n(120,0.026267737919362703)\n(150,0.03462545527769546)\n(180,0.018687206491885083)\n(210,0.02861637106095676)\n(240,0.012161746909496432)\n(270,0.01192416358220276)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530007475540_979245098",
      "id": "20180626-100435_1181734863",
      "dateCreated": "Jun 26, 2018 10:04:35 AM",
      "dateStarted": "Sep 11, 2018 3:33:55 PM",
      "dateFinished": "Sep 11, 2018 4:05:52 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Intrusion Detection",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:41 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eIntrusion Detection\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530018206824_-552242548",
      "id": "20180626-130326_301574963",
      "dateCreated": "Jun 26, 2018 1:03:26 PM",
      "dateStarted": "Sep 11, 2018 3:20:42 PM",
      "dateFinished": "Sep 11, 2018 3:20:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "def oneHotPipeline(inputCol: String): (Pipeline, String) \u003d {\n  val indexer \u003d new StringIndexer()\n    .setInputCol(inputCol)\n    .setOutputCol(inputCol + \"_indexed\")\n  \n  val encoder \u003d new OneHotEncoder()\n    .setInputCol(inputCol + \"_indexed\")\n    .setOutputCol(inputCol + \"_vec\")\n\n  val pipeline \u003d new Pipeline().setStages(Array(indexer, encoder))\n  (pipeline, inputCol + \"_vec\")\n}\n\ndef fitPipeline(data: DataFrame, k: Int): PipelineModel \u003d {\n  val (protoTypeEncoder, protoTypeVecCol) \u003d oneHotPipeline(\"protocol_type\")\n  val (serviceEncoder, serviceVecCol) \u003d oneHotPipeline(\"service\")\n  val (flagEncoder, flagVecCol) \u003d oneHotPipeline(\"flag\")\n\n  // Original columns, without label / string columns, but with new vector encoded cols\n  val assembleCols \u003d Set(data.columns: _*) -- \n    Seq(\"label\", \"protocol_type\", \"service\", \"flag\") ++\n    Seq(protoTypeVecCol, serviceVecCol, flagVecCol)\n  \n  val assembler \u003d new VectorAssembler()\n    .setInputCols(assembleCols.toArray)\n    .setOutputCol(\"featureVector\")\n\n  val scaler \u003d new StandardScaler()\n    .setWithStd(true)\n    .setWithMean(false)\n    .setInputCol(\"featureVector\")\n    .setOutputCol(\"scaledFeatureVector\")\n\n  val kMeans \u003d new KMeans()\n    .setSeed(Random.nextLong())\n    .setK(k)\n    .setMaxIter(40)\n    .setTol(1.0e-5)\n    .setPredictionCol(\"cluster\")\n    .setFeaturesCol(\"scaledFeatureVector\")\n\n  val pipeline \u003d new Pipeline().setStages(Array(protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kMeans))\n  pipeline.fit(data)\n}\n  \ndef intrusionDetector(dataframe: DataFrame): Unit \u003d {\n  val model \u003d fitPipeline(dataframe, 210)\n\n  val kMeansModel \u003d model.stages.last.asInstanceOf[KMeansModel]\n  val centroids \u003d kMeansModel.clusterCenters\n\n  val clustered \u003d model.transform(dataframe)\n  val threshold \u003d clustered.select(\"cluster\", \"scaledFeatureVector\").as[(Int, Vector)]\n    .map { case (cluster, vec) \u003d\u003e Vectors.sqdist(centroids(cluster), vec) }\n    .orderBy($\"value\".desc)\n    .take(100)\n    .last\n\n  val originalCols \u003d dataframe.columns\n  val anomalies \u003d clustered.filter { row \u003d\u003e\n    val cluster \u003d row.getAs[Int](\"cluster\")\n    val vec \u003d row.getAs[Vector](\"scaledFeatureVector\")\n    Vectors.sqdist(centroids(cluster), vec) \u003e\u003d threshold\n  }.select(originalCols.head, originalCols.tail:_*)\n\n  println(anomalies.first())\n}\n\nval dataframe \u003d spark\n  .read\n  .option(\"inferSchema\", true)\n  .option(\"header\", false)\n  .csv(\"/data/kddcup_1999_network_dataset/partially/kddcup.data_10_percent_corrected\")\n  .toDF(\"duration\", \"protocol_type\", \"service\", \"flag\",\n    \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n    \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n    \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\",\n    \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n    \"dst_host_count\", \"dst_host_srv_count\",\n    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n    \"label\")\n  \nintrusionDetector(dataframe)",
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 5:54:06 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "tableHide": false,
        "title": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "oneHotPipeline: (inputCol: String)(org.apache.spark.ml.Pipeline, String)\nfitPipeline: (data: org.apache.spark.sql.DataFrame, k: Int)org.apache.spark.ml.PipelineModel\nintrusionDetector: (dataframe: org.apache.spark.sql.DataFrame)Unit\ndataframe: org.apache.spark.sql.DataFrame \u003d [duration: int, protocol_type: string ... 40 more fields]\n[23,tcp,telnet,SF,104,276,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,1,1,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1,2,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,guess_passwd.]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530018281131_-86773000",
      "id": "20180626-130441_1307172991",
      "dateCreated": "Jun 26, 2018 1:04:41 PM",
      "dateStarted": "Sep 11, 2018 3:48:24 PM",
      "dateFinished": "Sep 11, 2018 4:08:59 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "Sep 11, 2018 3:20:42 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1530044597224_-1771895964",
      "id": "20180626-202317_2005299692",
      "dateCreated": "Jun 26, 2018 8:23:17 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Anomaly Detection Network",
  "id": "2DG9YNM1P",
  "angularObjects": {
    "2DS5RVF9U:shared_process": [],
    "2DRT81JGU:shared_process": [],
    "2DRB34CYN:shared_process": [],
    "2DPG6TC3B:shared_process": [],
    "2DQKTBYHZ:shared_process": [],
    "2DRU6QDM3:shared_process": [],
    "2DR3YHSSW:shared_process": [],
    "2DP6R35PR:shared_process": [],
    "2DQ4U6EQN:shared_process": [],
    "2DQF4GX5N:shared_process": [],
    "2DQK14MHH:shared_process": [],
    "2DP6FE781:shared_process": [],
    "2DQ92J8ZB:shared_process": [],
    "2DRV692E2:shared_process": [],
    "2DRB7AJGZ:shared_process": [],
    "2DSGQ23FT:shared_process": [],
    "2DQ2FCH17:shared_process": [],
    "2DREGP5Z3:shared_process": [],
    "2DQTEVV9K:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}